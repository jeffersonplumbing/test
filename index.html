<script type="text/javascript">
        var gk_isXlsx = false;
        var gk_xlsxFileLookup = {};
        var gk_fileData = {};
        function filledCell(cell) {
          return cell !== '' && cell != null;
        }
        function loadFileData(filename) {
        if (gk_isXlsx && gk_xlsxFileLookup[filename]) {
            try {
                var workbook = XLSX.read(gk_fileData[filename], { type: 'base64' });
                var firstSheetName = workbook.SheetNames[0];
                var worksheet = workbook.Sheets[firstSheetName];

                // Convert sheet to JSON to filter blank rows
                var jsonData = XLSX.utils.sheet_to_json(worksheet, { header: 1, blankrows: false, defval: '' });
                // Filter out blank rows (rows where all cells are empty, null, or undefined)
                var filteredData = jsonData.filter(row => row.some(filledCell));

                // Heuristic to find the header row by ignoring rows with fewer filled cells than the next row
                var headerRowIndex = filteredData.findIndex((row, index) =>
                  row.filter(filledCell).length >= filteredData[index + 1]?.filter(filledCell).length
                );
                // Fallback
                if (headerRowIndex === -1 || headerRowIndex > 25) {
                  headerRowIndex = 0;
                }

                // Convert filtered JSON back to CSV
                var csv = XLSX.utils.aoa_to_sheet(filteredData.slice(headerRowIndex)); // Create a new sheet from filtered array of arrays
                csv = XLSX.utils.sheet_to_csv(csv, { header: 1 });
                return csv;
            } catch (e) {
                console.error(e);
                return "";
            }
        }
        return gk_fileData[filename] || "";
        }
        </script><!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sonar Web App</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
            background-color: #f0f0f0;
        }
        button {
            padding: 15px 30px;
            font-size: 18px;
            background-color: #007bff;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
        }
        button:disabled {
            background-color: #6c757d;
        }
        p, h1, h2 {
            font-size: 20px;
            margin: 10px;
        }
        #results {
            text-align: left;
        }
    </style>
</head>
<body>
    <h1>Sonar Web App</h1>
    <p id="status">Ready</p>
    <p id="countdown" style="display: none;">Countdown: 5s</p>
    <h2>Results:</h2>
    <div id="results">
        <p id="distance1">Chirp 1: --</p>
        <p id="distance2">Chirp 2: --</p>
        <p id="distance3">Chirp 3: --</p>
        <p id="distance4">Chirp 4: --</p>
        <p id="distance5">Chirp 5: --</p>
    </div>
    <button id="startButton" onclick="startSonar()">Send Chirps</button>

    <script>
        const sampleRate = 44100;
        const startFreq = 10000;
        const endFreq = 15000;
        const chirpDuration = 0.01;
        const chirpGap = 0.1;
        const speedOfSound = 343;
        const metersToFeet = 3.28084;
        let audioContext;
        let mediaRecorder;
        let recordedChunks = [];
        let isPermissionGranted = false;

        async function requestMicPermission() {
            console.log('Requesting microphone permission...');
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                isPermissionGranted = true;
                document.getElementById('startButton').disabled = false;
                document.getElementById('status').textContent = 'Permission granted';
                console.log('Microphone permission granted');
                return stream;
            } catch (err) {
                document.getElementById('status').textContent = 'Microphone permission denied';
                document.getElementById('startButton').disabled = true;
                console.error('Permission error:', err.name, err.message);
            }
        }

        function generateChirp() {
            const frameCount = Math.floor(chirpDuration * sampleRate);
            const buffer = audioContext.createBuffer(1, frameCount, sampleRate);
            const data = buffer.getChannelData(0);
            const freqRange = endFreq - startFreq;
            for (let i = 0; i < frameCount; i++) {
                const t = i / sampleRate;
                const freq = startFreq + (freqRange * t / chirpDuration);
                data[i] = 0.5 * Math.sin(2 * Math.PI * freq * t);
            }
            return buffer;
        }

        async function startSonar() {
            console.log('startSonar called');
            if (!isPermissionGranted) {
                await requestMicPermission();
                if (!isPermissionGranted) return;
            }

            document.getElementById('status').textContent = 'Active Test';
            document.getElementById('countdown').style.display = 'block';
            let countdown = 5;
            document.getElementById('countdown').textContent = `Countdown: ${countdown}s`;
            const countdownInterval = setInterval(() => {
                countdown--;
                document.getElementById('countdown').textContent = `Countdown: ${countdown}s`;
                if (countdown <= 0) clearInterval(countdownInterval);
            }, 1000);

            document.getElementById('startButton').disabled = true;
            for (let i = 1; i <= 5; i++) {
                document.getElementById(`distance${i}`).textContent = `Chirp ${i}: --`;
            }

            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate });
                console.log('AudioContext created with sample rate:', sampleRate);
            } catch (err) {
                console.error('AudioContext error:', err);
                document.getElementById('status').textContent = 'AudioContext creation failed';
                document.getElementById('countdown').style.display = 'none';
                document.getElementById('startButton').disabled = false;
                return;
            }

            const chirpBuffer = generateChirp();
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream);
            recordedChunks = [];

            mediaRecorder.ondataavailable = (e) => {
                if (e.data.size > 0) recordedChunks.push(e.data);
                console.log('Recorded chunk received, size:', e.data.size);
            };

            mediaRecorder.onstop = () => processRecording(chirpBuffer);

            console.log('Starting recording...');
            mediaRecorder.start();

            // Play 5 chirps with gaps
            for (let i = 0; i < 5; i++) {
                const source = audioContext.createBufferSource();
                source.buffer = chirpBuffer;
                source.connect(audioContext.destination);
                source.start(audioContext.currentTime + i * (chirpDuration + chirpGap));
                console.log(`Playing chirp ${i + 1} at ${audioContext.currentTime + i * (chirpDuration + chirpGap)}`);
            }

            // Stop recording after 5 seconds
            setTimeout(() => {
                console.log('Stopping recording...');
                mediaRecorder.stop();
                stream.getTracks().forEach(track => track.stop());
                document.getElementById('countdown').style.display = 'none';
            }, 5000);
        }

        async function processRecording(chirpBuffer) {
            console.log('Processing recording...');
            document.getElementById('status').textContent = 'Processing...';

            try {
                const blob = new Blob(recordedChunks, { type: 'audio/webm' });
                const arrayBuffer = await blob.arrayBuffer();
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                const recordedData = audioBuffer.getChannelData(0);
                console.log('Recorded data length:', recordedData.length);

                const chirpData = chirpBuffer.getChannelData(0);
                const chirpLength = chirpData.length;
                const samplesPerChirp = Math.floor((chirpDuration + chirpGap) * sampleRate);

                for (let chirpIndex = 0; chirpIndex < 5; chirpIndex++) {
                    const startSample = Math.floor(chirpIndex * samplesPerChirp);
                    const endSample = Math.min(startSample + samplesPerChirp + chirpLength, recordedData.length);
                    const segment = recordedData.slice(startSample, endSample);

                    const correlationLength = segment.length + chirpData.length - 1;
                    const correlation = new Float32Array(correlationLength).fill(0);
                    for (let i = 0; i < segment.length; i++) {
                        for (let j = 0; j < chirpData.length; j++) {
                            if (i + j < correlationLength) {
                                correlation[i + j] += segment[i] * chirpData[j];
                            }
                        }
                    }

                    const ignoreSamples = Math.floor(chirpDuration * sampleRate) + 100;
                    let maxValue = -Infinity;
                    let maxIndex = 0;
                    for (let i = ignoreSamples; i < correlation.length; i++) {
                        if (correlation[i] > maxValue) {
                            maxValue = correlation[i];
                            maxIndex = i;
                        }
                    }

                    if (maxValue > 0.1) {
                        const rtt = (startSample + maxIndex) / sampleRate;
                        const distanceMeters = (speedOfSound * rtt) / 2;
                        const distanceFeet = distanceMeters * metersToFeet;
                        document.getElementById(`distance${chirpIndex + 1}`).textContent = `Chirp ${chirpIndex + 1}: ${distanceFeet.toFixed(2)} feet`;
                        console.log(`Chirp ${chirpIndex + 1} distance: ${distanceFeet.toFixed(2)} feet`);
                    } else {
                        document.getElementById(`distance${chirpIndex + 1}`).textContent = `Chirp ${chirpIndex + 1}: No echo`;
                        console.log(`Chirp ${chirpIndex + 1}: No echo detected`);
                    }
                }

                document.getElementById('status').textContent = 'Processing complete';
            } catch (err) {
                console.error('Processing error:', err);
                document.getElementById('status').textContent = 'Processing failed';
                for (let i = 1; i <= 5; i++) {
                    document.getElementById(`distance${i}`).textContent = `Chirp ${i}: Error`;
                }
            }

            document.getElementById('startButton').disabled = false;
            audioContext.close();
        }

        // Request permission on page load
        requestMicPermission();
    </script>
</body>
</html>
